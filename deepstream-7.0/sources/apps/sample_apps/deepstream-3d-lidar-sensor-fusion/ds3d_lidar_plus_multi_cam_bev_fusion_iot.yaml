%YAML 1.2
################################################################################
# SPDX-FileCopyrightText: Copyright (c) 2023-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: LicenseRef-NvidiaProprietary
#
# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
# property and proprietary rights in and to this material, related
# documentation and any modifications thereto. Any use, reproduction,
# disclosure or distribution of this material and related documentation
# without an express license agreement from NVIDIA CORPORATION or
# its affiliates is strictly prohibited.
################################################################################

---
name: video_source
type: ds3d::gstparsebin
link_to: videobridge_2d_to_3d
config_body:
  # cam_0: CAM_FRONT -> nvstreammux m.sink_0
  # cam_1: CAM_FRONT_RIGHT -> nvstreammux m.sink_1
  # cam_2: CAM_FRONT_LEFT -> nvstreammux m.sink_2
  # cam_3: CAM_BACK -> nvstreammux m.sink_3
  # cam_4: CAM_BACK_LEFT -> nvstreammux m.sink_4
  # cam_5: CAM_BACK_RIGHT -> nvstreammux m.sink_5
  # path of the frames, data file needs to be placed in order in this path
  parse_bin: >-
    multifilesrc loop=true location=data/nuscene/CAM_FRONT/%06d-CAM_FRONT.jpg ! image/jpeg, framerate=20/1 ! jpegparse ! nvv4l2decoder ! queue ! nvvideoconvert compute-hw=1 nvbuf-memory-type=2 ! video/x-raw(memory:NVMM), format=RGBA ! m.sink_0
    multifilesrc loop=true location=data/nuscene/CAM_FRONT_RIGHT/%06d-CAM_FRONT_RIGHT.jpg ! image/jpeg, framerate=20/1 ! jpegparse ! nvv4l2decoder ! queue ! nvvideoconvert compute-hw=1 nvbuf-memory-type=2 ! video/x-raw(memory:NVMM), format=RGBA ! m.sink_1
    multifilesrc loop=true location=data/nuscene/CAM_FRONT_LEFT/%06d-CAM_FRONT_LEFT.jpg ! image/jpeg, framerate=20/1 ! jpegparse ! nvv4l2decoder ! queue ! nvvideoconvert compute-hw=1 nvbuf-memory-type=2 ! video/x-raw(memory:NVMM), format=RGBA ! m.sink_2
    multifilesrc loop=true location=data/nuscene/CAM_BACK/%06d-CAM_BACK.jpg ! image/jpeg, framerate=20/1 ! jpegparse ! nvv4l2decoder ! queue ! nvvideoconvert compute-hw=1 nvbuf-memory-type=2 ! video/x-raw(memory:NVMM), format=RGBA ! m.sink_3
    multifilesrc loop=true location=data/nuscene/CAM_BACK_LEFT/%06d-CAM_BACK_LEFT.jpg ! image/jpeg, framerate=20/1 ! jpegparse ! nvv4l2decoder ! queue ! nvvideoconvert compute-hw=1 nvbuf-memory-type=2 ! video/x-raw(memory:NVMM), format=RGBA ! m.sink_4
    multifilesrc loop=true location=data/nuscene/CAM_BACK_RIGHT/%06d-CAM_BACK_RIGHT.jpg ! image/jpeg, framerate=20/1 ! jpegparse ! nvv4l2decoder ! queue ! nvvideoconvert compute-hw=1 nvbuf-memory-type=2 ! video/x-raw(memory:NVMM), format=RGBA ! m.sink_5
    nvstreammux name=m width=1600 height=900 batch-size=6 buffer-pool-size=6 nvbuf-memory-type=2 compute-hw=1 ! queue

# bridge (2d->3d)
---
name: videobridge_2d_to_3d
type: ds3d::databridge
link_to: multisensor_mixer.sink_1
in_caps: video/x-raw(memory:NVMM)
out_caps: ds3d/datamap
#with_queue: src
custom_lib_path: libnvds_3d_video_databridge.so
custom_create_function: createVideoBridge2d3d
config_body:
  surface_to_image: True
  # wrap nvbufsurface into color frame of ds3d::Frame2DGuard
  output_image_key: DS3D::ColorFrame
  # convert NvDsObjectMeta into array of ds3d::Object2DBbox with ds3d::FrameGuard
  output_object2d_key: DS3D::Object2DBboxKey


# read lidar data from file
---
name: ds3d_lidar_file_source
type: ds3d::dataloader
link_to: multisensor_mixer.sink_0
out_caps: ds3d/datamap
custom_lib_path: libnvds_lidarfileread.so
custom_create_function: createLidarFileLoader
config_body:
  #path of the frames, data file needs to be placed in order in this path
  data_config_file: lidar_nuscene_data_list.yaml
  points_num: 242180 #points num, change to 242180
  fixed_points_num: True
  lidar_datatype: FP32 #FP32 FP16 INT8 INT32, only support FP32 this version
  mem_type: gpu # choose [cpu gpu]
  gpu_id: 0
  mem_pool_size: 6
  element_size: 4
  element_stride: 5
  output_datamap_key: DS3D::LidarXYZI
  file_loop: True # False: read data normally True: read data circularly

# mixer
---
name: multisensor_mixer
type: ds3d::datamixer
link_to: lidar_alignment_filter
in_caps: ds3d/datamap
out_caps: ds3d/datamap
#with_queue: src
custom_lib_path: libnvds_3d_multisensor_mixer.so
custom_create_function: createMultiSensorMixer
config_body:
  #timeout in milliseconds;
  timeout: 50
  #force_sync == true will force mixer to wait for buffers from ALL inputs
  force_sync: true

# multi-sensor data fusion inference
---
name: bevfusion_inference
type: ds3d::datafilter
link_to: ds3d_fusion_msg_broker
in_caps: ds3d/datamap
out_caps: ds3d/datamap
custom_lib_path: libnvds_tritoninferfilter.so
custom_create_function: createLidarInferenceFilter
config_body:
  in_streams: [lidar]
  mem_pool_size: 2
  # datatype: FP32, FP16, INT8, INT32, INT16, UINT8, UINT16, UINT32, FP64, INT64, UINT64, BYTES, BOOL
  model_inputs:
    - name: input_image_0
      datatype: UINT8
      shape: [1, 900, 1600, 4]
      from: DS3D::ColorFrame_0+1
      is_2d_frame: true
    - name: input_image_1
      datatype: UINT8
      shape: [1, 900, 1600, 4]
      from: DS3D::ColorFrame_1+1
      is_2d_frame: true
    - name: input_image_2
      datatype: UINT8
      shape: [1, 900, 1600, 4]
      from: DS3D::ColorFrame_2+1
      is_2d_frame: true
    - name: input_image_3
      datatype: UINT8
      shape: [1, 900, 1600, 4]
      from: DS3D::ColorFrame_3+1
      is_2d_frame: true
    - name: input_image_4
      datatype: UINT8
      shape: [1, 900, 1600, 4]
      from: DS3D::ColorFrame_4+1
      is_2d_frame: true
    - name: input_image_5
      datatype: UINT8
      shape: [1, 900, 1600, 4]
      from: DS3D::ColorFrame_5+1
      is_2d_frame: true
    - name: input_lidar
      datatype: FP32
      shape: [242180, 4]
      from: DS3D::LidarXYZI+0

  gpu_id: 0
  # input tensor memory type after preprocess: GpuCuda, CpuCuda
  input_tensor_mem_type: GpuCuda
  labels:
    - car:
        color: [255, 158, 0]
    - truck:
        color: [255, 99, 71]
    - construction_vehicle:
        color: [233, 150, 70]
    - bus:
        color: [255, 69, 0]
    - trailer:
        color: [255, 140, 0]
    - barrier:
        color: [255, 201, 14]
    - motorcycle:
        color: [255, 61, 99]
    - bicycle:
        color: [220, 20, 60]
    - pedestrian:
        color: [0, 0, 230]
    - traffic_cone:
        color: [117, 22, 63]

  postprocess:
    score_threshold: 0.2
    3d_bbox_key: DS3D::Lidar3DBboxRawData

  #config_file: triton deploy,CAPI is edge deployment, GRPC is cloud deployment
  config_file: model_config_files/config_triton_bev_fusion_infer_grpc.pbtxt

# alignment (lidar->image calibration)
---
name: lidar_alignment_filter
type: ds3d::datafilter
link_to: bevfusion_inference
in_caps: ds3d/datamap
out_caps: ds3d/datamap
custom_lib_path: libnvds_3d_alignment_datafilter.so
custom_create_function: createLidarAlignmentFilter
config_body:
  disable_lidar_data_align: True
  cam_width: 1600
  cam_height: 900
  row_major: True
  # The below data settings are following camera order
  # [CAM_FRONT, CAM_FRONT_RIGHT, CAM_FRONT_LEFT, CAM_BACK, CAM_BACK_LEFT, CAM_BACK_RIGHT]
  output_cam_intrinsic_param_keys: [
      DS3D::Cam0_IntrinsicParm, DS3D::Cam1_IntrinsicParm, DS3D::Cam2_IntrinsicParm,
      DS3D::Cam3_IntrinsicParm, DS3D::Cam4_IntrinsicParm, DS3D::Cam5_IntrinsicParm]
  output_cam_intrinsic_mat_keys: [
      DS3D::Cam0_IntrinsicMatrix, DS3D::Cam1_IntrinsicMatrix, DS3D::Cam2_IntrinsicMatrix,
      DS3D::Cam3_IntrinsicMatrix, DS3D::Cam4_IntrinsicMatrix, DS3D::Cam5_IntrinsicMatrix]
  output_lidar_to_cam_extrinsic_mat_keys: [
    DS3D::LidarToCam0_ExtrinsicMatrix, DS3D::LidarToCam1_ExtrinsicMatrix, DS3D::LidarToCam2_ExtrinsicMatrix,
    DS3D::LidarToCam3_ExtrinsicMatrix, DS3D::LidarToCam4_ExtrinsicMatrix, DS3D::LidarToCam5_ExtrinsicMatrix]
  cam_intrinsic: [
      [1266.4172, 0.0000, 816.2670, 0.0000,
      0.0000, 1266.4172, 491.5071, 0.0000,
      0.0000, 0.0000, 1.0000, 0.0000],
      [1260.8474, 0.0000, 807.9682, 0.0000,
      0.0000, 1260.8474, 495.3344, 0.0000,
      0.0000, 0.0000, 1.0000, 0.0000],
      [1272.5979, 0.0000, 826.6155, 0.0000,
      0.0000, 1272.5979, 479.7517, 0.0000,
      0.0000, 0.0000, 1.0000, 0.0000],
      [809.2210, 0.0000, 829.2196, 0.0000,
      0.0000, 809.2210, 481.7784, 0.0000,
      0.0000, 0.0000, 1.0000, 0.0000],
      [1256.7415, 0.0000, 792.1126, 0.0000,
      0.0000, 1256.7415, 492.7757, 0.0000,
      0.0000, 0.0000, 1.0000, 0.0000],
      [1259.5137, 0.0000, 807.2529, 0.0000,
      0.0000, 1259.5137, 501.1958, 0.0000,
      0.0000, 0.0000, 1.0000, 0.0000]
      ]
  lidar_to_cam_extrisic: [
      [1.0000, 0.0035, 0.0068, 0.0119,
      0.0067, 0.0186, -0.9998, -0.3250,
      -0.0036, 0.9998, 0.0186, -0.7590],
      [0.5517, -0.8337, -0.0260, 0.2296,
      -0.0105, 0.0243, -0.9997, -0.3363,
      0.8340, 0.5517, 0.0046, -0.7516],
      [0.5729, 0.8193, 0.0211, -0.1943,
      0.0027, 0.0239, -0.9997, -0.3323,
      -0.8196, 0.5728, 0.0115, -0.7366],
      [-0.9999, 0.0047, -0.0098, -0.0023,
      0.0098, 0.0075, -0.9999, -0.2764,
      -0.0046, -1.0000, -0.0075, -0.9109],
      [-0.3171, 0.9481, 0.0249, -0.2409,
      0.0199, 0.0329, -0.9993, -0.2432,
      -0.9482, -0.3163, -0.0293, -0.4341],
      [-0.3569, -0.9335, -0.0355, 0.2342,
      -0.0054, 0.0401, -0.9992, -0.2734,
      0.9341, -0.3564, -0.0194, -0.4285]
      ]
  #cam input keys to ratain in the output datamap
  cam_input_keys: [DS3D::ColorFrame+1]
  max_points: 2073600
  mem_pool_size: 32
  align_to_intrinsic: false
  lidar_element_size: 4

---
name: ds3d_fusion_msg_broker
type: ds3d::gstparsebin
config_body:
  # payload-type: 1, minimum with 3d-bbox only. 2, protobuf with lidar data
  # start kafka server: $ docker run -p 9092:9092 apache/kafka:3.7.0
  # create kafka topic: $ bin/kafka-topics.sh --create --topic quick-test --bootstrap-server localhost:9092
  # consume kafka message : $ bin/kafka-console-consumer.sh --topic quick-test --bootstrap-server localhost:9092
  parse_bin: queue ! nvmsgconv config=bevfusion/msgconv_config_bevfusion.yaml payload-type=2 msg2p-newapi=true ! queue ! nvmsgbroker proto-lib=/opt/nvidia/deepstream/deepstream/lib/libnvds_kafka_proto.so conn-str=localhost;9092;quick-test topic=quick-test new-api=true sync=false async=true

# for debug
---
  name: debugdump
  type: ds3d::userapp
  eos_auto_stop: True
  enable_debug: False
  probe_buffer: True
